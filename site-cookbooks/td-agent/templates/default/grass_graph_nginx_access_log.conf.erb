# LTSV形式のログファイルを読み込む
<source>
  type tail
  id gg_nginx_access_log_tail
  format ltsv
  time_format %Y-%m-%d %H:%M:%S %z
  path /var/log/nginx/grass-graph.shitemil.works.access.log
  read_from_head true
  rotate_wait 60
  pos_file /var/log/td-agent/grass-graph.shitemil.works.access_log.pos
  tag gg.log.nginx
</source>

<match gg.log.nginx>
  type copy
  id gg_nginx_access_log_copy
  <store>
    # BigQueryの保存先テーブルを日毎に変化させる
    type record_reformer
    id gg_nginx_access_reformer
    enable_ruby true
    tag ${tag}.${time.strftime('%Y%m%d')}
  </store>
  <store>
    # fluent-plugin-datacounterでステータスコード別に集計する
    type datacounter
    id gg_nginx_access_log_datacounter
    count_interval 1m
    count_key status
    aggregate all
    tag gg.nginx.status.mackerel
    pattern1 2xx ^2\d\d$
    pattern2 3xx ^3\d\d$
    pattern3 4xx ^4\d\d$
    pattern4 5xx ^5\d\d$
  </store>
</match>

# fluent-plugin-mackerelによりサービスメトリックを投稿する
<match gg.nginx.status.mackerel>
  type mackerel
  id gg_nginx_access_log_mackerel
  buffer_type file
  buffer_path /var/log/td-agent/buffer/fluent.gg_nginx_access_log_mackerel*.buffer     #バッファデータの出力先ファイルパス
  buffer_chunk_limit 3k     #1chunkに保存できるデータサイズ上限
  buffer_queue_limit 3      #1queueに保存できるchunk数の上限
  retry_wait 30s   #再送を実行するまでの待ち時間
  retry_limit 5    #再送実施回数
  api_key <%= @mackerel_api_key %>
  service <%= @mackerel_service_name %>
  remove_prefix
  metrics_name <%= @color %>.access_num.${out_key}
  out_keys 2xx_count,3xx_count,4xx_count,5xx_count
</match>

<match gg.log.nginx.**>
  type forest
  subtype copy
  id gg_log_nginx_forest
  <template>
    <store>
      type bigquery
      id gg_log_nginx_bigquery
      method insert

      auth_method json_key
      json_key /etc/td-agent/.keys/gcp-credential-for-fluentd-jsonkey.json

      project a-know-home
      dataset aws_centrage_nginx_log

      flush_interval 1
      buffer_chunk_records_limit 1000
      buffer_queue_limit 1024
      num_threads 16

      auto_create_table true
      table gg_nginx_access_log_${tag_parts[-1]}

      time_format %s
      time_field time
      # scheme は home.a-know.me の access log と同じなので使い回す
      schema_path /etc/td-agent/settings/nginx_access_log_schema.json
      
      buffer_type file
      buffer_path /var/log/td-agent/buffer/fluent.gg_log_nginx_forest*.buffer     #バッファデータの出力先ファイルパス
      buffer_chunk_limit 3k     #1chunkに保存できるデータサイズ上限
      buffer_queue_limit 3      #1queueに保存できるchunk数の上限
      retry_wait 30s   #再送を実行するまでの待ち時間
      retry_limit 5    #再送実施回数
    </store>
  </template>
</match>
